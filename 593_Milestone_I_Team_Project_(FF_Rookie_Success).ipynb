{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Haz95PJ-8Za"
      },
      "source": [
        "# NFL Fantasy Football Rookie Success Analysis\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0AoR4rV_G8t"
      },
      "source": [
        "## Task 1: Install necessary packages and grab initial data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEKeRri2OqWy"
      },
      "outputs": [],
      "source": [
        "#TDL:\n",
        "#NFL Player Level Weekly Statistics (NFL PY) [2010-2025] - Done\n",
        "#College Football Stats (CFBD API) [2010-2025] - Done\n",
        "#Pre-Season Fantasy ADP (2025) - Done\n",
        "#Combine Results (2010-2025) - Done\n",
        "#NFL Draft Results (2025) - Done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7AmehcyPQHB"
      },
      "outputs": [],
      "source": [
        "#Install nfl_data_py\n",
        "#Note: This takes a while to install (3-5 mins.). Although, the libraries WiFi was slow when I did it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 689
        },
        "id": "6mb9_-X7PTe3",
        "outputId": "b90dba6e-9e79-4786-e3d4-cf69d070321e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting nfl_data_py\n",
            "  Using cached nfl_data_py-0.3.3-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy<2.0,>=1.0 (from nfl_data_py)\n",
            "  Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Collecting pandas<2.0,>=1.0 (from nfl_data_py)\n",
            "  Using cached pandas-1.5.3.tar.gz (5.2 MB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting appdirs>1 (from nfl_data_py)\n",
            "  Using cached appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting fastparquet>0.5 (from nfl_data_py)\n",
            "  Using cached fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: cramjam>=2.3 in /usr/local/lib/python3.12/dist-packages (from fastparquet>0.5->nfl_data_py) (2.11.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from fastparquet>0.5->nfl_data_py) (2025.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from fastparquet>0.5->nfl_data_py) (25.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.0,>=1.0->nfl_data_py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<2.0,>=1.0->nfl_data_py) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.1->pandas<2.0,>=1.0->nfl_data_py) (1.17.0)\n",
            "Using cached nfl_data_py-0.3.3-py3-none-any.whl (13 kB)\n",
            "Using cached appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Using cached fastparquet-2024.11.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "Using cached numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "Building wheels for collected packages: pandas\n",
            "  Building wheel for pandas (pyproject.toml) ... \u001b[?25l\u001b[?25hcanceled\n",
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0m^C\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-479800140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'install nfl_data_py'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_installation_commands.py\u001b[0m in \u001b[0;36m_pip_magic\u001b[0;34m(line)\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# Colab is set up such that pip does the right thing, and pip install\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m   \u001b[0;31m# will properly trigger the pip install warning.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pip {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m       \u001b[0m_pip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_send_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36mprint_previous_import_warning\u001b[0;34m(output)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprint_previous_import_warning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0;34m\"\"\"Prints a warning about previously imported packages.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m   \u001b[0mpackages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# display a list of packages using the colab-display-data mimetype, which\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_previously_imported_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_previously_imported_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m   \u001b[0;34m\"\"\"List all previously imported packages from a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m   \u001b[0minstalled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_extract_toplevel_packages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpip_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstalled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_pip.py\u001b[0m in \u001b[0;36m_extract_toplevel_packages\u001b[0;34m(pip_output)\u001b[0m\n\u001b[1;32m     37\u001b[0m   \u001b[0;34m\"\"\"Extract the list of toplevel packages associated with a pip install.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0mtoplevel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mps\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpackages_distributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mps\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0mtoplevel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mpackages_distributions\u001b[0;34m()\u001b[0m\n\u001b[1;32m    945\u001b[0m     \u001b[0mpkg_to_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mdist\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mpkg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_top_level_inferred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m             \u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpkg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpkg_to_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36m_top_level_declared\u001b[0;34m(dist)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_top_level_declared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 953\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'top_level.txt'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    954\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mread_text\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mPermissionError\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         ):\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoinpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0mread_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mread_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1013\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/codecs.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, errors)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "pip install nfl_data_py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "583da1fc",
        "outputId": "eeb02ef4-7b0b-4547-ca1c-7699164d1d59"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'nfl_data_py'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4262759900.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnfl_data_py\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnfl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'nfl_data_py'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import nfl_data_py as nfl\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKzdlvxuVurn"
      },
      "outputs": [],
      "source": [
        "#Find the different functions of nfl_data_py\n",
        "#dir(nfl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFVN5V4waq5M"
      },
      "outputs": [],
      "source": [
        "#Task 1: NFL Draft Results (2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jiz8JorJXHW9"
      },
      "outputs": [],
      "source": [
        "#NFL Draft Results (2025)\n",
        "picks_2015_2025 = nfl.import_draft_picks(range(2015, 2026))\n",
        "#picks_2025.columns\n",
        "\n",
        "filtered_picks_2015_2025 = picks_2015_2025[['season', 'round', 'pick', 'team', 'pfr_player_id', 'pfr_player_name', 'college', 'position']]\n",
        "\n",
        "#Print the results\n",
        "filtered_picks_2015_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwSByW7Aau5K"
      },
      "outputs": [],
      "source": [
        "#Task 2: Combine Results (2010-2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcNsaOdcXbX-"
      },
      "outputs": [],
      "source": [
        "#Combine Results (2010-2025)\n",
        "combine_results_2015_2025 = nfl.import_combine_data(range(2015, 2026))\n",
        "\n",
        "#There are 5062 rows of data\n",
        "#len(combine_results_2010_2025)\n",
        "\n",
        "#combine_results_2010_2025\n",
        "\n",
        "#Columns to Look At: ht, wt, forty, bench, vertical, broad_jump, cone, and shuttle\n",
        "combine_results_2015_2025.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s7CoFSd3Zigk"
      },
      "outputs": [],
      "source": [
        "#Task 3: College Football Stats (CFBD API) [2010-2025]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uob-7paqa0zl"
      },
      "outputs": [],
      "source": [
        "#API Key: vAxpOlW6/4/6GwI44zGXcenYCXf5AFP6fJ5wxYwkotfP9nQ3QYJwlG6rl+wOUiHR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wf6Eiu7zbO4m"
      },
      "outputs": [],
      "source": [
        "#Import the necessary libraries\n",
        "import requests\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lJRR8YMrbO7r"
      },
      "outputs": [],
      "source": [
        "API_KEY = \"vAxpOlW6/4/6GwI44zGXcenYCXf5AFP6fJ5wxYwkotfP9nQ3QYJwlG6rl+wOUiHR\"\n",
        "headers = {\"Authorization\": f\"Bearer {API_KEY}\"}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaIB3MOgbO-1"
      },
      "outputs": [],
      "source": [
        "url = \"https://api.collegefootballdata.com/stats/player/season?year=2024\"\n",
        "resp = requests.get(url, headers=headers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HbaosmkbgvD"
      },
      "outputs": [],
      "source": [
        "CFBD_data_2024 = resp.json()\n",
        "df = pd.json_normalize(CFBD_data_2024)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGLQa9DzbhUT"
      },
      "outputs": [],
      "source": [
        "#Unique values of the statType column\n",
        "df[\"statType\"].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WyO-pODqbhXq"
      },
      "outputs": [],
      "source": [
        "pivot_df = df.pivot_table(\n",
        "    index=[\"season\", \"playerId\", \"player\", \"position\", \"team\", \"conference\", \"category\"],\n",
        "    columns=\"statType\",\n",
        "    values=\"stat\",\n",
        "    aggfunc=\"sum\"\n",
        ").reset_index()\n",
        "\n",
        "pivot_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXjDglgWcV04"
      },
      "outputs": [],
      "source": [
        "#Quick Sanity Check: Ashton Jeanty Stats in 2024\n",
        "Ashton_Jeanty_stats_2024 = pivot_df[pivot_df[\"player\"] == \"Ashton Jeanty\"]\n",
        "Ashton_Jeanty_stats_2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6aNU22N1ciZd"
      },
      "outputs": [],
      "source": [
        "#TDL: Now, we need to grab the data from the years 2010-2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aY1nGttOdEB3"
      },
      "outputs": [],
      "source": [
        "#Empty list\n",
        "data_2010_2025 = []\n",
        "\n",
        "#Loop through 2010â€“2025\n",
        "for year in range(2010, 2026):\n",
        "    url = f\"https://api.collegefootballdata.com/stats/player/season?year={year}\"\n",
        "    resp = requests.get(url, headers=headers)\n",
        "\n",
        "    data = resp.json()\n",
        "    df_year = pd.json_normalize(data)\n",
        "\n",
        "    data_2010_2025.append(df_year)\n",
        "\n",
        "df_all = pd.concat(data_2010_2025, ignore_index=True)\n",
        "\n",
        "df_all.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVDCbTd1duba"
      },
      "outputs": [],
      "source": [
        "#There are 1292723 rows of data\n",
        "#len(df_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLL7JBp9eoPt"
      },
      "outputs": [],
      "source": [
        "pivot_2010_2025_df = df_all.pivot_table(\n",
        "    index=[\"season\", \"playerId\", \"player\", \"position\", \"team\", \"conference\", \"category\"],\n",
        "    columns=\"statType\",\n",
        "    values=\"stat\",\n",
        "    aggfunc=\"sum\"\n",
        ").reset_index()\n",
        "\n",
        "pivot_2010_2025_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnvf8xUue0p6"
      },
      "outputs": [],
      "source": [
        "pivot_2010_2025_df_sorted = pivot_2010_2025_df.sort_values(by=\"season\", ascending=False)\n",
        "pivot_2010_2025_df_sorted.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSqzM_hafTcn"
      },
      "outputs": [],
      "source": [
        "#Quick Sanity Check: Bryce Underwood Stats in 2025\n",
        "bryce_underwood_2025 = pivot_2010_2025_df[\n",
        "    (pivot_2010_2025_df[\"season\"] == 2025) &\n",
        "    (pivot_2010_2025_df[\"team\"] == \"Michigan\") &\n",
        "    (pivot_2010_2025_df[\"player\"] == \"Bryce Underwood\")\n",
        "]\n",
        "\n",
        "bryce_underwood_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UH7vVlSfp68"
      },
      "outputs": [],
      "source": [
        "#Quick Sanity Check: Hank Beatty Stats in 2025\n",
        "hank_beatty_2025 = pivot_2010_2025_df[\n",
        "    (pivot_2010_2025_df[\"season\"] == 2025) &\n",
        "    (pivot_2010_2025_df[\"team\"] == \"Illinois\") &\n",
        "    (pivot_2010_2025_df[\"player\"] == \"Hank Beatty\")\n",
        "]\n",
        "\n",
        "hank_beatty_2025"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vl5ZT-78gwrj"
      },
      "outputs": [],
      "source": [
        "#Task 4: Pre-Season Fantasy ADP (2025)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Azr20qMXhT8Y"
      },
      "outputs": [],
      "source": [
        "#Fetch the FantasyPros ADP Page\n",
        "url = \"https://www.fantasypros.com/nfl/adp/ppr-overall.php\"\n",
        "resp = requests.get(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1Wl4gorhULO"
      },
      "outputs": [],
      "source": [
        "#Parse Tables from the url\n",
        "tables = pd.read_html(resp.text)\n",
        "\n",
        "ADP_df = tables[0]\n",
        "ADP_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z4cI5JD6hUOm"
      },
      "outputs": [],
      "source": [
        "#TDL: Split the Player Team (Bye) Column to Player, Team and Bye\n",
        "ADP_df[[\"Player\", \"Team\", \"Bye\"]] = ADP_df[\"Player Team (Bye)\"].str.extract(r\"^(.*?)\\s+([A-Z]{2,3})\\s*\\((\\d+)\\)$\")\n",
        "ADP_df = ADP_df.drop(columns=[\"Player Team (Bye)\"])\n",
        "\n",
        "ADP_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LAUhvIpNiHPM"
      },
      "outputs": [],
      "source": [
        "#Task 5: NFL Player Level Weekly Statistics (NFL PY) [2010-2025]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4fnaXLH2iT0L"
      },
      "outputs": [],
      "source": [
        "#Find the different functions of nfl_data_py\n",
        "#dir(nfl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dC76YN82kP8T"
      },
      "outputs": [],
      "source": [
        "players_df = nfl.import_players()\n",
        "players_df = players_df[['gsis_id', 'display_name', 'pfr_id', 'position', 'college_name', 'rookie_season']]\n",
        "players_df = players_df[players_df['position'] == 'RB']\n",
        "players_df = players_df[players_df['rookie_season'] >= 2015]\n",
        "players_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Xz1r55Fkb9C"
      },
      "outputs": [],
      "source": [
        "#TDL: Get the data from 2010 to 2024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wM-U0SW9mN_2"
      },
      "outputs": [],
      "source": [
        "# grab all data from 2015-2024 seasons\n",
        "season_stats_2015_2024_df = nfl.import_seasonal_data(list(range(2015, 2025)), 'REG')\n",
        "\n",
        "# select only relevant columns\n",
        "relevant_cols = ['player_id','season','carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost', 'receptions', 'receiving_yards', 'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost']\n",
        "\n",
        "# merge on unique id and rookie year to only grab first year stats\n",
        "full_season_2015_2024_filtered = players_df.merge(\n",
        "    season_stats_2015_2024_df[relevant_cols],\n",
        "    left_on=['gsis_id', 'rookie_season'], right_on=['player_id','season'],\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "full_season_2015_2024_filtered.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ihFmYyvtnaRd"
      },
      "outputs": [],
      "source": [
        "#TDL: See all columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giLOU1JPncqW"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_columns\", None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSot4P0wmj3h"
      },
      "outputs": [],
      "source": [
        "#Quick Sanity Check: Matt Forte Stats\n",
        "#ESPN Stats: https://www.espn.com/nfl/player/stats/_/id/11278/matt-forte\n",
        "\n",
        "Matt_Forte_stats = full_season_stats_2010_2024[full_season_stats_2010_2024[\"display_name\"] == \"Matt Forte\"]\n",
        "Matt_Forte_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NkwdNeubmwCS"
      },
      "outputs": [],
      "source": [
        "#Note: There's an issue with nfl_data_py pulling in 2025 data. I'll monitor it, but in the meantime, we can download an Excel file to grab it.\n",
        "#Error: HTTPError: HTTP Error 404: Not Found"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4XOueRVhn6Dy"
      },
      "outputs": [],
      "source": [
        "#2024 Season Level Stats\n",
        "\n",
        "#season_stats_2010_2025_df = nfl.import_seasonal_data((list(range(2010, 2026))))\n",
        "#season_stats_2010_2025_df.columns\n",
        "#season_stats_2010_2025_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7aj4QaWAHw7"
      },
      "source": [
        "## Task 2: Join data and perform any cleaning or calculations required"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWR37pxSAdWs"
      },
      "source": [
        "We'll break our analysis down by position - To start, we'll create a general running back dataframe that will take the list of drafted running backs from 2010 to 2025 and bring in their combine results and college stats.\n",
        "\n",
        "For players drafted before 2025, we will bring in their first NFL season stats to see how they fared in their rookie year."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JknVcnaeAQrv"
      },
      "outputs": [],
      "source": [
        "# Filter draft results for only Running Backs\n",
        "rb_2015_2025 = filtered_picks_2015_2025[filtered_picks_2015_2025['position'] == 'RB']\n",
        "\n",
        "# Calculate pick number for the position in each draft\n",
        "rb_2015_2025 = rb_2015_2025.sort_values(by=['season','pick'])\n",
        "rb_2015_2025['rank'] = rb_2015_2025.groupby('season').cumcount() + 1\n",
        "rb_2015_2025['position_rank'] = rb_2015_2025['position'] + rb_2015_2025['rank'].astype(str)\n",
        "rb_2015_2025.drop(labels='rank', axis='columns', inplace=True)\n",
        "\n",
        "# there is a sinugular player who's pfr id is null - for simplicity, we will drop them for now\n",
        "rb_2015_2025 = rb_2015_2025[rb_2015_2025['pfr_player_id'].notna()]\n",
        "\n",
        "rb_2015_2025.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01JxhO9iDyfk"
      },
      "outputs": [],
      "source": [
        "# Add in combine data for each player\n",
        "# NFL Data Py provides a pfr_id which should make this initial join straightforward\n",
        "\n",
        "# filter combine dataframe for only the new columns we want to add\n",
        "combine_columns = ['pfr_id', 'ht', 'wt', 'forty', 'bench', 'vertical', 'broad_jump', 'cone', 'shuttle']\n",
        "\n",
        "# merge dataframes on the pfr_id which has slightly different names between the two frames\n",
        "rb_2015_2025 = rb_2015_2025.merge(\n",
        "    combine_results_2015_2025[combine_columns],\n",
        "    left_on='pfr_player_id', right_on ='pfr_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# drop the duplicate pfr column from combine dataframe\n",
        "rb_2015_2025.drop(labels='pfr_id', axis='columns', inplace=True)\n",
        "\n",
        "# create unique_id column that will be used to join with college career stats\n",
        "rb_2015_2025['unique_id'] = (\n",
        "    rb_2015_2025['pfr_player_name'].str.lower().replace(r'[^a-z0-9]', '', regex=True) +\n",
        "    rb_2015_2025['position'].str.lower() +\n",
        "    rb_2015_2025['college'].str.lower().replace(r'[^a-z0-9]', '', regex=True)\n",
        ")\n",
        "\n",
        "rb_2015_2025.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OkAT8byIIWiU"
      },
      "outputs": [],
      "source": [
        "# Now, we will aggregate career college stats for each player then join with draft and combine data\n",
        "# We will perform this for just rushing and receiving categories since those are the most relevant for running backs\n",
        "\n",
        "# filter for just RBs and Rushing stats to make future analysis more efficient\n",
        "college_rush_df = df_all[df_all['category'].isin(['rushing'])]\n",
        "\n",
        "# there is a weird nuance in the data where position is sometimes listed as \"?\" for some players\n",
        "# since we are looking at rushing both here and in the draft + combine stats, we'll assume those ? are running backs to ensure more matches\n",
        "college_rush_df['position'] = college_rush_df['position'].str.replace('?', 'RB', regex=False)\n",
        "\n",
        "college_rush_df = college_rush_df.pivot_table(\n",
        "    index=[\"season\", \"playerId\", \"player\", \"position\", \"team\", \"conference\", \"category\"],\n",
        "    columns=\"statType\",\n",
        "    values=\"stat\",\n",
        "    aggfunc=\"sum\"\n",
        ").reset_index()\n",
        "\n",
        "# drop YPC column for now - we will recalculate after aggregating to career level by dividing yards by number of carries\n",
        "college_rush_df.drop(labels='YPC', axis='columns', inplace=True)\n",
        "\n",
        "# rename stat columns to clarify these are college stats\n",
        "column_mapping = {\n",
        "    'CAR':'college_carries',\n",
        "    'LONG':'college_long',\n",
        "    'TD':'college_tds',\n",
        "    'YDS':'college_yards'\n",
        "}\n",
        "\n",
        "college_rush_df.rename(columns=column_mapping,inplace=True)\n",
        "\n",
        "# also change naming within column of \"state\" to \"st.\" to ensure more matches with draft and combine data later on\n",
        "college_rush_df['team'] = college_rush_df['team'].str.replace('State', 'St.', regex=False)\n",
        "\n",
        "# ensure that these columns are cast as numeric so aggregation functions succeed\n",
        "cols_to_convert = ['college_carries', 'college_tds', 'college_yards', 'college_long']\n",
        "college_rush_df[cols_to_convert] = college_rush_df[cols_to_convert].apply(pd.to_numeric, errors='coerce')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M11jvNX7Pis2"
      },
      "outputs": [],
      "source": [
        "# aggregate stats to player level for college career stats\n",
        "# one nuance we need to account for is the transfer portal - schools in the draft are always the last college they attended\n",
        "\n",
        "# per player id, we'll sort to the latest season they played\n",
        "college_data_sorted = college_rush_df.sort_values(by=['playerId', 'season'])\n",
        "\n",
        "# group by playerId and aggregate\n",
        "college_career_stats = college_data_sorted.groupby(['playerId', 'player', 'position']).agg(\n",
        "    # grab the last team name and year - our sort earlier ensures this grabs the last team they played for\n",
        "    college=('team', 'last'),\n",
        "    year=('season','max'),\n",
        "\n",
        "    # stat totals, specific to each category\n",
        "    college_carries=('college_carries', 'sum'),\n",
        "    college_tds=('college_tds', 'sum'),\n",
        "    college_yards=('college_yards', 'sum'),\n",
        "    college_long=('college_long', 'max')\n",
        ").reset_index()\n",
        "\n",
        "# create \"unique id\" column that can be used to join to draft + combine table\n",
        "college_career_stats['unique_id'] = (\n",
        "    college_career_stats['player'].str.lower().replace(r'[^a-z0-9]', '', regex=True) +\n",
        "    college_career_stats['position'].str.lower() +\n",
        "    college_career_stats['college'].str.lower().replace(r'[^a-z0-9]', '', regex=True)\n",
        ")\n",
        "\n",
        "# so as it turns out, we had a couple instances were a player suddenly had different IDs in the dataset (Cj and CJ names that resulted in different IDs)\n",
        "# because of this, we'll aggregate one more time based on the unique_id since based on the duplicates, they are intended to be the same player\n",
        "\n",
        "college_career_stats = college_career_stats.groupby('unique_id').agg(\n",
        "    college_carries=('college_carries', 'sum'),\n",
        "    college_tds=('college_tds', 'sum'),\n",
        "    college_yards=('college_yards', 'sum'),\n",
        "    college_long=('college_long', 'max')\n",
        ").reset_index()\n",
        "\n",
        "#recalculate college ypc now that we are at a career level\n",
        "college_career_stats['college_ypc'] = round(college_career_stats['college_yards']/college_career_stats['college_carries'],1)\n",
        "\n",
        "college_career_stats.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "liQkJO0PUr1b"
      },
      "outputs": [],
      "source": [
        "# and now, using the unique id, we'll bring in the career college stats for each player\n",
        "rb_2015_2025['unique_id'] = rb_2015_2025['unique_id'].str.strip().str.lower()\n",
        "college_career_stats['unique_id'] = college_career_stats['unique_id'].str.strip().str.lower()\n",
        "\n",
        "stat_columns = ['college_carries', 'college_tds', 'college_yards', 'college_long', 'college_ypc']\n",
        "\n",
        "rb_2015_2025 = rb_2015_2025.merge(\n",
        "    college_career_stats[stat_columns + ['unique_id']],\n",
        "    on='unique_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "rb_2015_2025.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mruOa_hrXQf"
      },
      "outputs": [],
      "source": [
        "stat_cols = ['pfr_id','carries', 'rushing_yards', 'rushing_tds', 'rushing_fumbles', 'rushing_fumbles_lost', 'receptions', 'receiving_yards', 'receiving_tds', 'receiving_fumbles', 'receiving_fumbles_lost']\n",
        "\n",
        "full_rb_2015_2025_df = rb_2015_2025.merge(\n",
        "    full_season_2015_2024_filtered[stat_cols],\n",
        "    left_on='pfr_player_id', right_on='pfr_id',\n",
        "    how='left'\n",
        ")\n",
        "\n",
        "# for any nan values in the stat columns, we'll replace with 0 so the fantasy calculation works correctly\n",
        "full_rb_2015_2025_df[stat_cols] = full_rb_2015_2025_df[stat_cols].fillna(0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwTCv7pJPbzB"
      },
      "outputs": [],
      "source": [
        "# now, we'll define a function to calculate fantasy points based on ppr scoring system\n",
        "def calculate_fantasy_points(row):\n",
        "    points = (\n",
        "        row['rushing_yards'] * 0.1 +\n",
        "        row['rushing_tds'] * 6 +\n",
        "        row['rushing_fumbles_lost'] * -2 +\n",
        "        row['receiving_yards'] * 0.1 +\n",
        "        row['receptions'] * 1 +\n",
        "        row['receiving_tds'] * 6 +\n",
        "        row['receiving_fumbles_lost'] * -2\n",
        "    )\n",
        "\n",
        "    return round(points, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DHY841nEPcyF"
      },
      "outputs": [],
      "source": [
        "# now we can apply the function and caluclate fantasy points scored for each player in their rookie year\n",
        "\n",
        "full_rb_2015_2025_df['fantasy_points'] = full_rb_2015_2025_df.apply(calculate_fantasy_points, axis=1)\n",
        "\n",
        "# let's see who the highest scoring rookie was over these years!\n",
        "full_rb_2015_2025_df.sort_values(by='fantasy_points', ascending=False).head(20)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}